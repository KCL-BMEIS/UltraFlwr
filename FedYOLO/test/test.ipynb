{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################\n",
      "# CLIENT RESULTS #\n",
      "##################\n",
      "\n",
      "/home/localssk23/UltraFlwr\n",
      "Ultralytics 8.3.48 🚀 Python-3.12.2 torch-2.5.1+cu124 CPU (12th Gen Intel Core(TM) i7-12800H)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/localssk23/backup/soumya/env/fedlytics/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/localssk23/UltraFlwr/datasets/baseline/partitions/client_0/valid/labels.cache... 6 images, 6 backgrounds, 0 corrupt: 100%|██████████| 12/12 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         12         12    0.00285        0.5       0.31      0.252\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 0.0ms loss, 7.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val17\u001b[0m\n",
      "Ultralytics 8.3.48 🚀 Python-3.12.2 torch-2.5.1+cu124 CPU (12th Gen Intel Core(TM) i7-12800H)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/localssk23/UltraFlwr/datasets/baseline/valid/labels.cache... 25 images, 0 backgrounds, 0 corrupt: 100%|██████████| 25/25 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25         48     0.0052      0.487      0.291      0.219\n",
      "Speed: 0.8ms preprocess, 45.3ms inference, 0.0ms loss, 7.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val18\u001b[0m\n",
      "/home/localssk23/UltraFlwr\n",
      "Ultralytics 8.3.48 🚀 Python-3.12.2 torch-2.5.1+cu124 CPU (12th Gen Intel Core(TM) i7-12800H)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/localssk23/UltraFlwr/datasets/baseline/partitions/client_1/valid/labels.cache... 7 images, 6 backgrounds, 0 corrupt: 100%|██████████| 13/13 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         13         13    0.00242      0.364      0.208      0.162\n",
      "Speed: 0.8ms preprocess, 44.6ms inference, 0.0ms loss, 8.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val19\u001b[0m\n",
      "Ultralytics 8.3.48 🚀 Python-3.12.2 torch-2.5.1+cu124 CPU (12th Gen Intel Core(TM) i7-12800H)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/localssk23/UltraFlwr/datasets/baseline/valid/labels.cache... 25 images, 0 backgrounds, 0 corrupt: 100%|██████████| 25/25 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25         48     0.0055      0.423      0.337       0.21\n",
      "Speed: 0.9ms preprocess, 47.6ms inference, 0.0ms loss, 8.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val20\u001b[0m\n",
      "\n",
      "\n",
      "##############################\n",
      "# FINAL CONSOLIDATED METRICS #\n",
      "##############################\n",
      "  Class  mAP@0.5:0.95_local_0  mAP@0.5:0.95_global_0  mAP@0.5:0.95_local_1  mAP@0.5:0.95_global_1\n",
      "cheetah              0.503484               0.438227               0.32494               0.419473\n",
      "  human              0.000000               0.000000               0.00000               0.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from extract_final_save_from_client import extract_results_path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from FedYOLO.config import HOME, SPLITS_CONFIG, SERVER_CONFIG\n",
    "\n",
    "DATASET_NAME = SPLITS_CONFIG['dataset_name']\n",
    "NUM_ROUNDS = SERVER_CONFIG['rounds']\n",
    "\n",
    "#! HUGE DIFFERENCES BETWEEN SYSTEMS REGARDING FILES PATHS AND LOGGING. NEED TO IN-DEPTH TEST THIS.\n",
    "\n",
    "#####################\n",
    "# CLIENT EVALUATION #\n",
    "#####################\n",
    "\n",
    "def get_client_metrics(client_number, dataset_name, home_path):\n",
    "    # Extract paths\n",
    "    print(home_path)\n",
    "    client_model_weights_path = extract_results_path(f\"{home_path}/logs/client_{client_number}_log_{dataset_name}.txt\")\n",
    "    weights = f\"{home_path}/{client_model_weights_path}/weights/best.pt\"\n",
    "    \n",
    "    # Load and validate local model\n",
    "    client_model = YOLO(weights)\n",
    "    client_metrics = client_model.val(data=f'{home_path}/datasets/{dataset_name}/partitions/client_{client_number}/data.yaml', verbose=False)\n",
    "    \n",
    "    # Create local model metrics table\n",
    "    client_table = pd.DataFrame({\n",
    "        'Class': list(client_metrics.names.values()),\n",
    "        'mAP@0.5:0.95': client_metrics.box.maps.tolist()\n",
    "    })\n",
    "    \n",
    "    # Extract global model weights\n",
    "    client_global_model_weights_path = extract_results_path(f\"{home_path}/logs/client_{client_number}_log_{dataset_name}.txt\")\n",
    "    global_weights = f\"{home_path}/{client_global_model_weights_path}/weights/best.pt\"\n",
    "    \n",
    "    # Load and validate global model\n",
    "    client_global_model = YOLO(global_weights)\n",
    "    client_global_metrics = client_global_model.val(data=f'{home_path}/datasets/{dataset_name}/data.yaml', verbose=False)\n",
    "    \n",
    "    # Create global model metrics table\n",
    "    client_global_table = pd.DataFrame({\n",
    "        'Class': list(client_global_metrics.names.values()),\n",
    "        'mAP@0.5:0.95': client_global_metrics.box.maps.tolist()\n",
    "    })\n",
    "    \n",
    "    # Combine local and global model metrics\n",
    "    combined_table = pd.merge(client_table, client_global_table, on='Class', how='inner')\n",
    "    combined_table.columns = ['Class', 'mAP@0.5:0.95_local', 'mAP@0.5:0.95_global']\n",
    "\n",
    "    del client_model\n",
    "    del client_global_model\n",
    "    \n",
    "    return combined_table\n",
    "\n",
    "print('##################')\n",
    "print('# CLIENT RESULTS #')\n",
    "print('##################')\n",
    "print()\n",
    "client_0_metrics_table = get_client_metrics(0, DATASET_NAME, HOME)\n",
    "client_1_metrics_table = get_client_metrics(1, DATASET_NAME, HOME)\n",
    "combined_table = pd.merge(client_0_metrics_table, client_1_metrics_table, on='Class', how='inner')\n",
    "combined_table.columns = ['Class', 'mAP@0.5:0.95_local_0', 'mAP@0.5:0.95_global_0', 'mAP@0.5:0.95_local_1', 'mAP@0.5:0.95_global_1']\n",
    "print()\n",
    "print()\n",
    "print('##############################')\n",
    "print('# FINAL CONSOLIDATED METRICS #')\n",
    "print('##############################')\n",
    "print(combined_table.to_string(index=False))\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################\n",
      "# SERVER RESULTS #\n",
      "##################\n",
      "\n",
      "WARNING ⚠️ validating an untrained model YAML will result in 0 mAP.\n",
      "Ultralytics 8.3.48 🚀 Python-3.12.2 torch-2.5.1+cu124 CPU (12th Gen Intel Core(TM) i7-12800H)\n",
      "YOLO11n_baseline summary (fused): 238 layers, 2,582,542 parameters, 12,870 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/localssk23/UltraFlwr/datasets/baseline/partitions/client_0/valid/labels.cache... 6 images, 6 backgrounds, 0 corrupt: 100%|██████████| 12/12 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         12         12      0.003       0.45      0.177      0.118\n",
      "                     0          6         10      0.006        0.9      0.353      0.236\n",
      "                     1          1          2          0          0          0          0\n",
      "Speed: 0.6ms preprocess, 39.5ms inference, 0.0ms loss, 8.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val21\u001b[0m\n",
      "WARNING ⚠️ validating an untrained model YAML will result in 0 mAP.\n",
      "Ultralytics 8.3.48 🚀 Python-3.12.2 torch-2.5.1+cu124 CPU (12th Gen Intel Core(TM) i7-12800H)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/localssk23/UltraFlwr/datasets/baseline/partitions/client_1/valid/labels.cache... 7 images, 6 backgrounds, 0 corrupt: 100%|██████████| 13/13 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         13         13    0.00253      0.409      0.241      0.198\n",
      "                     0          7         11    0.00505      0.818      0.482      0.396\n",
      "                     1          1          2          0          0          0          0\n",
      "Speed: 0.9ms preprocess, 43.7ms inference, 0.0ms loss, 7.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val22\u001b[0m\n",
      "WARNING ⚠️ validating an untrained model YAML will result in 0 mAP.\n",
      "Ultralytics 8.3.48 🚀 Python-3.12.2 torch-2.5.1+cu124 CPU (12th Gen Intel Core(TM) i7-12800H)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/localssk23/UltraFlwr/datasets/baseline/valid/labels.cache... 25 images, 0 backgrounds, 0 corrupt: 100%|██████████| 25/25 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         25         48    0.00533      0.449      0.294      0.199\n",
      "                     0         25         39     0.0107      0.897      0.588      0.398\n",
      "                     1          3          9          0          0          0          0\n",
      "Speed: 0.9ms preprocess, 44.8ms inference, 0.0ms loss, 7.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val23\u001b[0m\n",
      "  Class  mAP@0.5:0.95_client_0  mAP@0.5:0.95_client_1  mAP@0.5:0.95_global\n",
      "0     0                0.23604               0.396361             0.398224\n",
      "1     1                0.00000               0.000000             0.000000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "NUM_ROUNDS = 3\n",
    "\n",
    "#####################\n",
    "# SERVER EVALUATION #\n",
    "#####################\n",
    "print('##################')\n",
    "print('# SERVER RESULTS #')\n",
    "print('##################')\n",
    "print()\n",
    "\n",
    "server_model = YOLO(f\"{HOME}/yolo11n_{DATASET_NAME}.yaml\")\n",
    "server_model_weights_path = f\"{HOME}/weights/model_round_{NUM_ROUNDS}_{DATASET_NAME}.pt\"\n",
    "server_model.model.load_state_dict(torch.load(server_model_weights_path)['model'].state_dict(), strict=False)\n",
    "\n",
    "server_model_client0_metrics = server_model.val(data=f'{HOME}/datasets/{DATASET_NAME}/partitions/client_0/data.yaml', verbose=True)\n",
    "server_model_client1_metrics = server_model.val(data=f'{HOME}/datasets/{DATASET_NAME}/partitions/client_1/data.yaml', verbose=True)\n",
    "server_model_global_metrics = server_model.val(data=f'{HOME}/datasets/{DATASET_NAME}/data.yaml', verbose=True)\n",
    "\n",
    "server_model_client0_table = pd.DataFrame({\n",
    "    'Class': list(server_model_client0_metrics.names.values()),\n",
    "    'mAP@0.5:0.95': server_model_client0_metrics.box.maps.tolist()\n",
    "})\n",
    "\n",
    "server_model_client1_table = pd.DataFrame({\n",
    "    'Class': list(server_model_client1_metrics.names.values()),\n",
    "    'mAP@0.5:0.95': server_model_client1_metrics.box.maps.tolist()\n",
    "})\n",
    "\n",
    "server_model_global_table = pd.DataFrame({\n",
    "    'Class': list(server_model_global_metrics.names.values()),\n",
    "    'mAP@0.5:0.95': server_model_global_metrics.box.maps.tolist()\n",
    "})\n",
    "\n",
    "# First, merge client0 and client1 tables\n",
    "server_model_combined_table = pd.merge(server_model_client0_table, server_model_client1_table, on='Class', how='inner')\n",
    "\n",
    "# Then, merge the result with the global table\n",
    "server_model_combined_table = pd.merge(server_model_combined_table, server_model_global_table, on='Class', how='inner')\n",
    "\n",
    "# Rename the columns\n",
    "server_model_combined_table.columns = ['Class', 'mAP@0.5:0.95_client_0', 'mAP@0.5:0.95_client_1', 'mAP@0.5:0.95_global']\n",
    "\n",
    "print(server_model_combined_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedlytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
